OpenAI 发布对齐研究工作合集
https://zhuanlan.zhihu.com/p/622188645

OpenAI 预测七年内超级 AI 将问世，并宣布「20% 算力用来解决失控问题」，哪些信息值得关注？
https://www.zhihu.com/question/610639130/answers/updated
https://openai.com/blog/introducing-superalignment

Ten Levels of AI Alignment Difficulty
https://www.lesswrong.com/posts/EjgfreeibTXRx9Ham/ten-levels-of-ai-alignment-difficulty

万字长文概览大语言模型对齐（欺骗性对齐、可扩展的监管、机械可解释性、工具性目标趋同
https://zhuanlan.zhihu.com/p/643161870

对Hugging Face开源模型精准投毒！LLM切脑后变身PoisonGPT，用虚假事实洗脑60亿人
https://zhuanlan.zhihu.com/p/642616786

Overview of Model Editing
https://zhuanlan.zhihu.com/p/609177437

Knowledge Neurons in Pretrained Transformers 北大-微软使用积分梯度从Transformer的FFN层提取“知识神经元”
https://zhuanlan.zhihu.com/p/611481317

Locating and Editing Factual Associations in GPT
https://blog.csdn.net/qq_28385535/article/details/128312436
https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247554176&idx=3&sn=08759b617e3cf11f9fdedab3a97346e3&chksm=ebb72c54dcc0a54281cfef69a230f3c0f9e9e576517912b927efb152547c236a92e432c3eb10&scene=27
https://arxiv.org/abs/2202.05262

Locating and Editing Factual Associations in GPT翻译
https://blog.csdn.net/qq_28385535/article/details/128312436

Transformer Feed-Forward Layers Are Key-Value Memories
https://zhuanlan.zhihu.com/p/611278136
https://arxiv.org/abs/2012.14913

Can LMs Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge
https://arxiv.org/abs/2305.01651

MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions
https://arxiv.org/abs/2305.14795

Decouple knowledge from paramters for plug-and-play language modeling
https://arxiv.org/abs/2305.11564
https://github.com/hannibal046/pluglm

Dissecting Recall of Factual Associations in Auto-Regressive Language Models
https://arxiv.org/abs/2304.14767

Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering
https://arxiv.org/abs/2204.04581

Inseq: An Interpretability Toolkit for Sequence Generation Models
https://arxiv.org/abs/2302.13942

Explaining How Transformers Use Context to Build Predictions
https://arxiv.org/abs/2305.12535

Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space
https://arxiv.org/abs/2203.14680

Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT
https://arxiv.org/abs/2305.13417
https://github.com/shacharkz/visualizing-the-information-flow-of-gpt

Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute
https://arxiv.org/abs/2301.10448

RARR: Researching and Revising What Language Models Say, Using Language Models
https://arxiv.org/abs/2210.08726

Complex Claim Verification with Evidence Retrieved in the Wild
https://arxiv.org/abs/2305.11859

Using Natural Language Explanations to Rescale Human Judgments
https://arxiv.org/abs/2305.14770

When to Read Documents or QA History: On Unified and Selective Open-domain QA
https://arxiv.org/abs/2306.04176

Augmenting Self-attention with Persistent Memory
https://arxiv.org/abs/1907.01470

Editing Large Language Models: Problems, Methods, and Opportunities
https://arxiv.org/abs/2305.13172

大模型知识Out该怎么办？浙大团队探索大模型参数更新的方法—模型编辑
https://www.php.cn/faq/552888.html

Eliciting Latent Predictions from Transformers with the Tuned Lens
https://arxiv.org/abs/2303.08112

积分梯度：一种新颖的神经网络可视化方法
https://www.spaces.ac.cn/archives/7533

Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space
https://arxiv.org/abs/2203.14680

LM-Debugger: An Interactive Tool for Inspection and Intervention in Transformer-Based Language Models
https://arxiv.org/abs/2204.12130
https://github.com/mega002/lm-debugger

interpreting GPT: the logit lens
https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens
