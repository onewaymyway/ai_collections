Stable Diffusion爱好者常说的LoRa是什么？
https://zhuanlan.zhihu.com/p/610031713

论文阅读：LORA-大型语言模型的低秩适应
https://zhuanlan.zhihu.com/p/611557340

Alpaca-lora 在消费级显卡上训练你自己的 ChatGPT！
https://zhuanlan.zhihu.com/p/614913980
https://github.com/tloen/alpaca-lora

LoCon相对于LoRA的改进
https://zhuanlan.zhihu.com/p/612133434

QLoRA：一种高效LLMs微调方法，48G内存可调65B 模型，调优模型Guanaco 堪比Chatgpt的99.3%
https://zhuanlan.zhihu.com/p/632229856

QLoRA的实测记录
https://zhuanlan.zhihu.com/p/632398047

开源原驼（Guanaco）及背后的QLoRA技术，将微调65B模型的显存需求从780GB以上降低到48GB以下，效果直逼GPT-4，技术详解
https://zhuanlan.zhihu.com/p/632236718
QLoRA: Efficient Finetuning of Quantized LLMs
https://arxiv.org/abs/2305.14314

如何从数据集中自动识别高质量的指令数据-IFD指标的使用
https://zhuanlan.zhihu.com/p/658128530
https://arxiv.org/abs/2308.12032
https://github.com/MingLiiii/Cherry_LLM

Firefly(流萤): 中文对话式大语言模型
https://www.shangyexinzhi.com/article/7399473.html

【OpenLLM 007】大模型炼丹术之小参数撬动大模型-万字长文全面解读PEFT参数高效微调技术
https://zhuanlan.zhihu.com/p/625502729

deepspeed入门教程
https://zhuanlan.zhihu.com/p/630734624

《Universal Language Model Fine-tuning for Text Classification》论文笔记
https://blog.csdn.net/weixin_44815943/article/details/123870564

微软也搞起了开源小模型！利用 OpenAI 的 ChatGPT 和 GPT-4 训练，实力碾压当前最强开源模型
https://zhuanlan.zhihu.com/p/639212768

O-LoRA: 针对LLM的“灾难遗忘”解决方案
https://zhuanlan.zhihu.com/p/663034986

中文LLaMA&Alpaca大语言模型词表扩充+预训练+指令精调
https://zhuanlan.zhihu.com/p/631360711

Instruction Tuning with Human Curriculum
https://arxiv.org/abs/2310.09518

EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling
https://www.semanticscholar.org/paper/EMO%3A-Earth-Mover-Distance-Optimization-for-Language-Ren-Wu/36b88e6cf9cd5fa4809602f365287cb2201f8350

InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4
https://arxiv.org/abs/2308.12067

OpenChat: Advancing Open-source Language Models with Mixed-Quality Data
https://arxiv.org/abs/2309.11235

微软发布Orca2，“调教式”教会小规模大语言模型如何推理！
https://zhuanlan.zhihu.com/p/670516349
Orca 2: Teaching Small Language Models How to Reason
https://arxiv.org/abs/2311.11045


如何从数据集中自动识别高质量的指令数据-IFD指标的使用
https://zhuanlan.zhihu.com/p/658128530

[林知/术] 全参数微调LLaMA-2-70B备忘
https://zhuanlan.zhihu.com/p/666613055
https://arxiv.org/abs/2308.12032

DeepSpeed之ZeRO系列：将显存优化进行到底
https://basicv8vc.github.io/posts/zero/

WizardLM：赋予大型语言模型遵循复杂指令的能力
https://zhuanlan.zhihu.com/p/643162614
独家采访WizardLM团队，详解WizardCoder/Math超越GPT4/ChatGPT的RLEIF算法
https://it.sohu.com/a/715204130_121119001
