如何评测一个大模型？（微软亚洲研究院 ）
https://zhuanlan.zhihu.com/p/656726594

LLM Evaluation 如何评估一个大模型？
https://zhuanlan.zhihu.com/p/644373658

放弃评测大模型，普林斯顿大学已经开始评估Prompt了，提出Prompt评估框架
https://zhuanlan.zhihu.com/p/644546392

大模型数据--评测数据汇总
https://zhuanlan.zhihu.com/p/658725797

"牧羊人"Shepherd中文版批判模型微调
https://zhuanlan.zhihu.com/p/665269693
https://huggingface.co/datasets/frankminors123/chinese-shepherd-critic-dataset

PandaLM: 评估大模型的大模型, 保护隐私、可靠、可复现，三行代码即可调用
https://zhuanlan.zhihu.com/p/626391857
PandaLM：面向LLM指令调优(论文翻译)
https://zhuanlan.zhihu.com/p/645760817
https://arxiv.org/abs/2306.05087

JudgeLM: Fine-tuned Large Language Models are Scalable Judges
https://arxiv.org/abs/2310.17631

Evaluating Large Language Models at Evaluating Instruction Following
https://arxiv.org/abs/2310.07641

Generative Judge for Evaluating Alignment
https://arxiv.org/abs/2310.05470
评论能力强于GPT-4，上交开源13B评估大模型Auto-J
https://zhuanlan.zhihu.com/p/662639644
https://github.com/GAIR-NLP/auto-j

Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena
https://arxiv.org/abs/2306.05685

利用GPT4等进行大模型自动打分是否靠谱：3种评价方法、4大缺陷及4大应对方案工作解读
http://lechangxia.cc/gpt4/411.html


