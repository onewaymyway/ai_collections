智源语义向量模型BGE: "C-Pack: Packaged Resources To Advance General Chinese Embedding"
https://zhuanlan.zhihu.com/p/663579886
https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md

LLM时代下的embedding检索模型进化探索
https://zhuanlan.zhihu.com/p/663821101
One Embedder, Any Task: Instruction-Finetuned Text Embeddings
https://arxiv.org/abs/2212.09741
https://instructor-embedding.github.io/

为什么Embedding模型在大语言模型中很重要？
https://zhuanlan.zhihu.com/p/647280030

Towards General Text Embeddings with Multi-stage Contrastive Learning
https://arxiv.org/abs/2308.03281
GTE(MTEB Top2)的成功秘诀--大力出奇迹
https://zhuanlan.zhihu.com/p/652472924
https://huggingface.co/thenlper/gte-large-zh

增强常见问题解答搜索引擎：在 Elasticsearch 中利用 KNN 的力量
https://blog.csdn.net/UbuntuTouch/article/details/134071714

Text embedding 模型总结
https://blog.csdn.net/dzysunshine/article/details/133674250

OpenAI: Text and Code Embeddings by Contrastive Pre-Training
https://zhuanlan.zhihu.com/p/496870495

[论文尝鲜]我们是否要用检索来预训练自回归语言模型？
https://zhuanlan.zhihu.com/p/651320363
Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study
https://arxiv.org/abs/2304.06762

InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
https://arxiv.org/abs/2310.07713

开卷翻到毒蘑菇？浅谈大模型检索增强（RAG）的鲁棒性
https://zhuanlan.zhihu.com/p/668991666

关于检索增强下大模型知识边界的探索
https://zhuanlan.zhihu.com/p/648106984
Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation
https://arxiv.org/abs/2307.11019

Large Language Models for Information Retrieval: A Survey 大模型用于信息检索综述-论文阅读
https://zhuanlan.zhihu.com/p/666414155
大模型RAG检索增强问答如何评估：噪声、拒答、反事实、信息整合四大能力评测任务探索
https://zhuanlan.zhihu.com/p/664265300
Benchmarking Large Language Models in Retrieval-Augmented Generation
https://arxiv.org/abs/2309.01431

Ever: Mitigating Hallucination in Large Language Models through Real-Time Verification and Rectification
https://arxiv.org/abs/2311.09114

维基百科+大模型打败幻觉！斯坦福WikiChat性能碾压GPT-4，准确率高达97.3%
https://zhuanlan.zhihu.com/p/675857387
WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia
https://arxiv.org/abs/2305.14292
https://github.com/stanford-oval/WikiChat

Retrieve Anything To Augment Large Language Models
https://arxiv.org/abs/2310.07554

大模型RAG问答技术架构及核心模块：从Embedding、prompt-embedding到Reranker
https://zhuanlan.zhihu.com/p/676499800

Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study
https://arxiv.org/abs/2304.06762
[论文尝鲜]我们是否要用检索来预训练自回归语言模型？
https://zhuanlan.zhihu.com/p/651320363

OpenAI是如何将RAG的准确率优化至98%的
https://zhuanlan.zhihu.com/p/704291371

OpenAI新的向量技术(embedding)-俄罗斯套娃表征学习
https://zhuanlan.zhihu.com/p/680273451

万字长文总结检索增强 LLM
https://zhuanlan.zhihu.com/p/655272123

Large Language Models Struggle to Learn Long-Tail Knowledge
https://arxiv.org/abs/2211.08411v2
Google-ICML2023: 大型语言模型难以学习长尾知识，检索增强LLM前景广阔
https://zhuanlan.zhihu.com/p/646876000


